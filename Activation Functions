### Activation Functions
ActivationFunctions is a Python class that provides implementations of commonly used activation functions for neural networks. This class offers methods to compute activation functions such as sigmoid, ReLU (Rectified Linear Unit), and hyperbolic tangent (tanh), as well as their derivatives for backpropagation.

###### Sigmoid:
  - $$\sigma(z) = \frac{1}{1 + e^{-z}}$$

###### ReLU (Rectified Linear Unit) Function:

###### Tanh (Hyperbolic Tangent) Function:


##### Installation
To use the ActivationFunctions class, you can simply copy the class definition into your Python project. There are no additional dependencies required.

##### Usage
Instantiate the ActivationFunctions class, and then you can use its methods to compute activations and their derivatives.
